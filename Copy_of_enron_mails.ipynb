{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AOt38HrC76Tg"
      ]
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.cluster import KMeans \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "from scipy.stats import multivariate_normal as mvn\n",
        "import nltk\n",
        "import os\n",
        "import random\n",
        "\n",
        "import string\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "import os, sys, email,re\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "TSDcOvH476Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "5JyRA8SUeVpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef68af3-bad5-429b-a433-bb998942bdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "ECwPEYVhbQwO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "d15cc044-3eee-4d5b-dbd4-828a7d1441b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v2jR0Xcq76Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/Data/emails.csv',nrows = 35000)\n",
        "df.shape"
      ],
      "metadata": {
        "_uuid": "7e378415a2eea9de2c91cb8d8d0cd5cc2f1ed7db",
        "trusted": true,
        "id": "JKYp-1vs76Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LVQI0NvTqZcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Analysis Starts Here\n",
        "## Use the Email module to extract raw text"
      ],
      "metadata": {
        "_uuid": "0b5c69f4a63625167cf53f569cc4ed20b56ebff2",
        "id": "2U7QcNbb76Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emails = list(map(email.parser.Parser().parsestr,df['message']))\n",
        "\n",
        "headings  = emails[0].keys()\n",
        "\n",
        "for key in headings:\n",
        "    df[key] = [doc[key] for doc in emails]\n",
        "\n",
        "df"
      ],
      "metadata": {
        "_uuid": "aa4a64c122f30a8fdda1173e0f067ba034e6bd99",
        "trusted": true,
        "id": "8M97EXDc76Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_raw_text(emails):\n",
        "    email_text = []\n",
        "    for email in emails.walk():\n",
        "        if email.get_content_type() == 'text/plain':\n",
        "            email_text.append(email.get_payload())\n",
        "    return ''.join(email_text)\n",
        "\n",
        "df['body'] = list(map(get_raw_text, emails))\n",
        "df.head()\n",
        "df['user'] = df['file'].map(lambda x: x.split('/')[0])"
      ],
      "metadata": {
        "_uuid": "978057cd2567e0da3b80d4087fd8e7109033f21b",
        "trusted": true,
        "id": "VxnKfx0a76S2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total number of emails: %d' %len(df))\n",
        "print('------------')\n",
        "print('Number of unique received: %d '%df['To'].nunique())\n",
        "print('------------')\n",
        "print('Number of unique Sent: %d '%df['From'].nunique())"
      ],
      "metadata": {
        "_uuid": "e2fa353a4954a74489beb4aeef32603572d13c10",
        "trusted": true,
        "id": "9pjbKtGh76TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'].map(lambda x : int(x.split()[3]))"
      ],
      "metadata": {
        "id": "CIS7UhGHU2f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Month'] = df['Date'].map(lambda x : x.split()[2])\n",
        "df['Year'] = df['Date'].map(lambda x : int(x.split()[3]))\n",
        "df['Day'] = df['Date'].map(lambda x : x.split()[0][:-1])\n",
        "\n",
        "indices = (df['Year'] > 1995) & (df['Year'] <= 2004)\n",
        "plt.figure(figsize = (10,6))\n",
        "figure1 = df.loc[indices].groupby('Year')['body'].count().plot()"
      ],
      "metadata": {
        "id": "Y91qTxMuUVsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Most frequent Senders and receivers of Emails"
      ],
      "metadata": {
        "_uuid": "1add953c811099a0d5e03881b0261811198ea12a",
        "id": "jtIX8JYn76TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_frequent = df.groupby('user')['file'].count().sort_values(ascending = False)[:30]\n",
        "top_10_frequent"
      ],
      "metadata": {
        "_uuid": "662dc0d0be9d78805dcce9151a77b5424dec84d2",
        "trusted": true,
        "id": "W24lFs_B76TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "top_10_frequent.plot(kind = 'bar')"
      ],
      "metadata": {
        "_uuid": "704dc23c870123d6600983a4a2db674440961d40",
        "trusted": true,
        "id": "uxFXhBOW76TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check whether emails were to a single person or multiple people"
      ],
      "metadata": {
        "_uuid": "8ee19edd8114d68c86e77b4f8d08dfabd7509f62",
        "id": "CGHRKVbh76TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data):\n",
        "    if data is not None:\n",
        "        temp = data.split(',')\n",
        "        if len(temp) == 1:\n",
        "            return 'Direct'\n",
        "        else:\n",
        "            return 'Multiple'\n",
        "    else:\n",
        "        return 'Empty'\n",
        "df['Direct_or_multi'] = df['To'].apply(split_data)"
      ],
      "metadata": {
        "_uuid": "9f0855ff38fd5cba944d507ebdc485b8432e353c",
        "trusted": true,
        "id": "1xQTNhGf76TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 most frequent emailers\n"
      ],
      "metadata": {
        "_uuid": "a476fd382b2b00d4e806f1165139bbaeba618907",
        "id": "ny9DqQe776TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('user')['Direct_or_multi'].value_counts().sort_values(ascending=False)[:15]"
      ],
      "metadata": {
        "_uuid": "82d66cad464de2c83a0e2424a773f09755e2b857",
        "trusted": true,
        "id": "iWwD6FxC76TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['body'][9]"
      ],
      "metadata": {
        "id": "pEGDB82ux_ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean the subject columns"
      ],
      "metadata": {
        "_uuid": "2f58d01ae7e02714493c625be6b1bc0252363dc2",
        "id": "L8Ja1e5W76TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_column(data):\n",
        "    if data is not None:\n",
        "        stopwords_list = stopwords.words('english')\n",
        "        data =  data.lower()\n",
        "        data = re.sub('re:', '', data)\n",
        "        data = re.sub('-', '', data)\n",
        "        data = re.sub('_', '', data)\n",
        "        # Remove data between square brackets\n",
        "        data =re.sub('\\[[^]]*\\]', '', data)\n",
        "        data = re.sub(r'[^\\w\\s]','',data)\n",
        "        data = re.sub(r'\\n',' ',data)\n",
        "        data = re.sub(r'[0-9]+','',data)\n",
        "        # removes punctuation \n",
        "        p = re.compile(r'<.*?>')\n",
        "        data = re.sub(r\"\\'ve\", \" have \", data)\n",
        "        data = re.sub(r\"can't\", \"cannot \", data)\n",
        "        data = re.sub(r\"n't\", \" not \", data)\n",
        "        data = re.sub(r\"I'm\", \"I am\", data)\n",
        "        data = re.sub(r\" m \", \" am \", data)\n",
        "        data = re.sub(r\"\\'re\", \" are \", data)\n",
        "        data = re.sub(r\"\\'d\", \" would \", data)\n",
        "        data = re.sub(r\"\\'ll\", \" will \", data)\n",
        "        \n",
        "        data = p.sub('', data)\n",
        "        if 'forwarded by:' in data:\n",
        "            data = data.split('subject')[1]\n",
        "        data = data.strip()\n",
        "        return data\n",
        "    return 'No Subject'\n",
        "\n",
        "\n",
        "df['Subject_new'] = df['Subject'].apply(clean_column)\n",
        "df['body_new'] = df['body'].apply(clean_column)"
      ],
      "metadata": {
        "_uuid": "d711ae74515769e2c6986f8b542192a06e41dfa8",
        "trusted": true,
        "id": "w5hI6raP76TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['body','body_new']].head(10)"
      ],
      "metadata": {
        "_uuid": "5b3f1aa3af57a45199f6f755c0d3c0fd0c4f89de",
        "trusted": true,
        "id": "ra8HhvEN76TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Subject','Subject_new']].head(10)"
      ],
      "metadata": {
        "id": "KuIvJ6l2y6K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "stopwords = set(STOPWORDS)\n",
        "to_add = ['FW', 'ga', 'httpitcappscorpenroncomsrrsauthemaillinkaspidpage', 'cc', 'aa', 'aaa', 'aaaa',\n",
        "         'hou', 'cc', 'etc', 'subject', 'pm']\n",
        "\n",
        "for i in to_add:\n",
        "    stopwords.add(i)"
      ],
      "metadata": {
        "_uuid": "9809ae509c60a46a0e2c3d48bbc5d57c0569fec0",
        "trusted": true,
        "id": "dpWJl8qE76TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualise Email Subject"
      ],
      "metadata": {
        "_uuid": "25b47b86da74b06b02526beede75009eafa519bc",
        "id": "SoPzq2vV76TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordcloud = WordCloud(\n",
        "              collocations = False,\n",
        "              width=1600, height=800,\n",
        "              background_color='white',\n",
        "              stopwords=stopwords,\n",
        "              max_words=150,\n",
        "              random_state=42).generate(' '.join(df['Subject_new']))\n",
        "print(wordcloud)\n",
        "plt.figure(figsize=(9,8))\n",
        "fig = plt.figure(1)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "2c60b4e6df35b43838533a1b767951d1ad8bd07c",
        "trusted": true,
        "id": "7Pzli-2F76TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF tranformation for K-means algorithm"
      ],
      "metadata": {
        "_uuid": "2d4e159568edeef437994f71b111211786e03e26",
        "id": "HXxmhaYv76TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "data = df['body_new']\n",
        "\n",
        "tf_idf_vectorizor = TfidfVectorizer(stop_words = stopwords, max_features = 5000)\n",
        "tf_idf = tf_idf_vectorizor.fit_transform(data)\n",
        "tf_idf_norm = normalize(tf_idf)\n",
        "tf_idf_array = tf_idf_norm.toarray()\n",
        "pd.DataFrame(tf_idf_array, columns=tf_idf_vectorizor.get_feature_names()).head()"
      ],
      "metadata": {
        "_uuid": "d24536f6bdb6c02a40ae3c991947e2974d91fa4d",
        "trusted": true,
        "id": "QDfs16x976TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
        "    ax = ax or plt.gca()\n",
        "    \n",
        "    if covariance.shape == (2, 2):\n",
        "        U, s, Vt = np.linalg.svd(covariance)\n",
        "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
        "        width, height = 2 * np.sqrt(s)\n",
        "    else:\n",
        "        angle = 0\n",
        "        width, height = 2 * np.sqrt(covariance)\n",
        "    \n",
        "    for nsig in range(1, 4):\n",
        "        ax.add_patch(Ellipse(position, nsig * width, nsig * height, angle, **kwargs))\n"
      ],
      "metadata": {
        "id": "SajyMhfD0uf6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# K-means Implementation"
      ],
      "metadata": {
        "_uuid": "98df5260d4eb50d8483e420673b5d80bd1040eb0",
        "id": "xMeDP7ud76Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "number_clusters = range(1, 7)\n",
        "\n",
        "kmeans = [KMeans(n_clusters=i, max_iter = 600) for i in number_clusters]\n",
        "\n",
        "sklearn_pca = PCA(n_components = 2)\n",
        "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
        "score = [kmeans[i].fit(Y_sklearn).score(Y_sklearn) for i in range(len(kmeans))]\n",
        "score = [i*-1 for i in score]\n",
        "\n",
        "plt.plot(number_clusters, score)\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "4ed2230dbfb8b273b0f85a150f250cf26af3f4e5",
        "trusted": true,
        "id": "jxfEDWcG76Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 3\n",
        "sklearn_pca = PCA(n_components = 2)\n",
        "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
        "kmeans = KMeans(n_clusters= n_clusters, max_iter=600)\n",
        "fitted = kmeans.fit(Y_sklearn)\n",
        "prediction = kmeans.predict(Y_sklearn)\n",
        "\n",
        "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=prediction ,s=50, cmap='viridis')\n",
        "\n",
        "centers2 = fitted.cluster_centers_\n",
        "plt.scatter(centers2[:, 0], centers2[:, 1],c='black', s=300, alpha=0.6);"
      ],
      "metadata": {
        "_uuid": "c1a364850092c057485d1fe2b15ab38649527e4e",
        "trusted": true,
        "id": "Dxo2MECa76Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,8))\n",
        "from scipy.spatial.distance import cdist\n",
        "def plot_kmeans(kmeans, X, n_clusters=3, rseed=0, ax=None):\n",
        "    labels = kmeans.fit_predict(X)\n",
        "\n",
        "    ax = ax or plt.gca()\n",
        "    ax.axis('equal')\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
        "\n",
        "    centers = kmeans.cluster_centers_\n",
        "    radii = [cdist(X[labels == i], [center]).max() for i, center in enumerate(centers)]\n",
        "    for c, r in zip(centers, radii):\n",
        "        ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.5, zorder=1))\n",
        "        \n",
        "plot_kmeans(kmeans, Y_sklearn)"
      ],
      "metadata": {
        "id": "B9W9DHxV0WxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gaussian Mixuture Model Implementation"
      ],
      "metadata": {
        "id": "vDWD8uThfnbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "sklearn_pca = PCA(n_components = 2)\n",
        "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
        "gmm = GaussianMixture(n_components=3, covariance_type='full').fit(Y_sklearn)\n",
        "prediction_gmm = gmm.predict(Y_sklearn)\n",
        "probs = gmm.predict_proba(Y_sklearn)\n",
        "\n",
        "centers = np.zeros((3,2))\n",
        "for i in range(3):\n",
        "    density = mvn(cov=gmm.covariances_[i], mean=gmm.means_[i]).logpdf(Y_sklearn)\n",
        "    centers[i, :] = Y_sklearn[np.argmax(density)]\n",
        "\n",
        "plt.figure(figsize = (10,8))\n",
        "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=prediction_gmm ,s=50, cmap='viridis')\n",
        "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);"
      ],
      "metadata": {
        "id": "Xc78eEZafmnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,8))\n",
        "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1],c=prediction_gmm ,s=50, cmap='viridis', zorder=1)\n",
        "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);\n",
        "\n",
        "for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
        "    draw_ellipse(pos, covar, alpha=w*.75)"
      ],
      "metadata": {
        "id": "f12y9uUs1J-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimal Clusters"
      ],
      "metadata": {
        "_uuid": "081852a5e777527742826ab575162ab34c2e2fdb",
        "id": "AOt38HrC76Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.style as style\n",
        "\n",
        "range_n_clusters = [2, 3, 4, 5, 6]\n",
        "silhouette_avg_n_clusters = []\n",
        "\n",
        "def optimal_cluster(x):\n",
        "  for n_clusters in range_n_clusters:\n",
        "      # Create a subplot with 1 row and 2 columns\n",
        "      fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "      fig.set_size_inches(18, 7)\n",
        "\n",
        "      # The 1st subplot is the silhouette plot\n",
        "      # The silhouette coefficient can range from -1, 1 but in this example all\n",
        "      # lie within [-0.1, 1]\n",
        "      ax1.set_xlim([-0.1, 1])\n",
        "      # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "      # plots of individual clusters, to demarcate them clearly.\n",
        "      ax1.set_ylim([0, len(Y_sklearn) + (n_clusters + 1) * 10])\n",
        "\n",
        "      # Initialize the clusterer with n_clusters value and a random generator\n",
        "      # seed of 10 for reproducibility.\n",
        "      if x == \"K\" or x == \"k\" :\n",
        "        clusterer = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "      elif x==\"G\"or x==\"g\" :\n",
        "        clusterer = GaussianMixture(n_components=n_clusters, random_state=42)\n",
        "\n",
        "      cluster_labels = clusterer.fit_predict(Y_sklearn)\n",
        "\n",
        "      # The silhouette_score gives the average value for all the samples.\n",
        "      # This gives a perspective into the density and separation of the formed\n",
        "      # clusters\n",
        "      silhouette_avg = silhouette_score(Y_sklearn, cluster_labels)\n",
        "      print(\"For n_clusters =\", n_clusters,\n",
        "            \"The average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "      silhouette_avg_n_clusters.append(silhouette_avg)\n",
        "      # Compute the silhouette scores for each sample\n",
        "      sample_silhouette_values = silhouette_samples(Y_sklearn, cluster_labels)\n",
        "\n",
        "      y_lower = 10\n",
        "      for i in range(n_clusters):\n",
        "          # Aggregate the silhouette scores for samples belonging to\n",
        "          # cluster i, and sort them\n",
        "          ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "          ith_cluster_silhouette_values.sort()\n",
        "\n",
        "          size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "          y_upper = y_lower + size_cluster_i\n",
        "\n",
        "          color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "          ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "          # Label the silhouette plots with their cluster numbers at the middle\n",
        "          ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "          # Compute the new y_lower for next plot\n",
        "          y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "      ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "      ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "      ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "      # The vertical line for average silhouette score of all the values\n",
        "      ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "      ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "      ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "      # 2nd Plot showing the actual clusters formed\n",
        "      colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "      ax2.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1], marker='.', s=30, lw=0, alpha=0.7, c=colors, edgecolor='k')\n",
        "\n",
        "      # Labeling the clusters\n",
        "      if x == \"K\" or x == \"k\" :\n",
        "        centers = clusterer.cluster_centers_\n",
        "      elif x==\"G\"or x==\"g\" :\n",
        "        centers = np.zeros((n_clusters,2))\n",
        "        for i in range(n_clusters):\n",
        "          density = mvn(cov=gmm.covariances_[i], mean=gmm.means_[i]).logpdf(Y_sklearn)\n",
        "          centers[i, :] = Y_sklearn[np.argmax(density)]\n",
        "      \n",
        "      # Draw white circles at cluster centers\n",
        "      ax2.scatter(centers[:, 0], centers[:, 1], marker='o', c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "      for i, c in enumerate(centers):\n",
        "          ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor='k')\n",
        "\n",
        "      ax2.set_title(\"The visualization of the clustered data.\")\n",
        "      ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "      ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "      plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                    \"with n_clusters = %d\" % n_clusters), fontsize=14, fontweight='bold')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  style.use(\"fivethirtyeight\")\n",
        "  plt.plot(range_n_clusters, silhouette_avg_n_clusters)\n",
        "  plt.xlabel(\"Number of Clusters (k)\")\n",
        "  plt.ylabel(\"silhouette score\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dqgBlCHg7TRw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"K-means Optimal Clusters\")\n",
        "optimal_cluster(\"K\")"
      ],
      "metadata": {
        "id": "PKWTv8LS9ue7",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Gaussian Mixuture Model Optimal Clusters\")\n",
        "optimal_cluster(\"G\")"
      ],
      "metadata": {
        "id": "CD092koY-IcE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Extracting top features"
      ],
      "metadata": {
        "_uuid": "edcb4686bae60bfd19c972e4b1b2bc71e61b9e1a",
        "trusted": true,
        "id": "G7sMXG8a76Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
        "    labels = np.unique(prediction)\n",
        "    dfs = []\n",
        "    for label in labels:\n",
        "        id_temp = np.where(prediction==label) \n",
        "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) \n",
        "        sorted_means = np.argsort(x_means)[::-1][:n_feats] \n",
        "        features = tf_idf_vectorizor.get_feature_names()\n",
        "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
        "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
        "        dfs.append(df)\n",
        "    return dfs\n",
        "dfs = get_top_features_cluster(tf_idf_array, prediction, 20)"
      ],
      "metadata": {
        "_uuid": "3006fc8dcb19e59d277e4604b44f04fb94d535a6",
        "trusted": true,
        "id": "q0W6at7l76Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[0][:15])"
      ],
      "metadata": {
        "_uuid": "e7a30f21a8faa82bdf870fb857c04afad15df51e",
        "trusted": true,
        "id": "zVQdpMFs76Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[1][:15])"
      ],
      "metadata": {
        "_uuid": "b0395236ca855fedae890f0157ea471466aa0d5f",
        "trusted": true,
        "id": "jTDCvuUt76Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[2][:15])"
      ],
      "metadata": {
        "_uuid": "22745a940f217f01df17afe91cebc06b12cf05c2",
        "trusted": true,
        "id": "F68ZhJ4U76Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs[2]"
      ],
      "metadata": {
        "id": "GoyvD1gInWrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, df in enumerate(dfs):\n",
        "    df.to_csv('df_'+str(i)+'.csv')"
      ],
      "metadata": {
        "_uuid": "b1fbd1f0b77293f46e924f2c76ae660ba2585e3e",
        "trusted": true,
        "id": "SoywtgqN76Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_features(dfs):\n",
        "    fig = plt.figure(figsize=(14,12))\n",
        "    x = np.arange(len(dfs[0]))\n",
        "    for i, df in enumerate(dfs):\n",
        "        ax = fig.add_subplot(1, len(dfs), i+1)\n",
        "        ax.set_title(\"Cluster: \"+ str(i), fontsize = 14)\n",
        "        ax.spines[\"top\"].set_visible(False)\n",
        "        ax.spines[\"right\"].set_visible(False)\n",
        "        ax.set_frame_on(False)\n",
        "        ax.get_xaxis().tick_bottom()\n",
        "        ax.get_yaxis().tick_left()\n",
        "        ax.ticklabel_format(axis='x', style='sci', scilimits=(-2,2))\n",
        "        ax.barh(x, df.score, align='center', color='#40826d')\n",
        "        yticks = ax.set_yticklabels(df.features)\n",
        "    plt.show();\n",
        "plot_features(dfs)"
      ],
      "metadata": {
        "_uuid": "c52396e0aa85f040a5b6706ec6610cc3f3d3954b",
        "trusted": true,
        "id": "WG8habey76Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "21b9a00b553acc8fe37be6498a581024fbcb2674",
        "trusted": true,
        "id": "c0P5sa3076Tl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}